# fiveFunctionsOfTorchTensor

This is the first assignment for Deep Learning with PyTorch: Zero to GANs course. Here five common tesors functions available in PyTorch is discussed. These functions are extensively used in deep learning for various operations such as initialization, matrix multiplication, reshaping, and flattening of tensors.

Here are some specific reasons why these functions are important:

1,2. torch.zeros() and torch.randn(): These functions are used to initialize tensors with predefined shapes and fill them with zeros or random values. Initializing tensors with proper values is important for model training and convergence.

3. torch.matmul(): This function performs matrix multiplication between two tensors. Matrix multiplication is a fundamental operation in deep learning, and it is used in various layers of neural networks such as fully connected layers and convolutional layers.

4. torch.reshape(): This function reshapes a tensor into a new shape without changing its data. Reshaping is often required when feeding tensors into different layers of a neural network.

5. torch.flatten(): This function flattens a tensor into a one-dimensional tensor. Flattening is often required when feeding tensors into fully connected layers of a neural network.
